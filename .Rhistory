library(lmerTest)
p_data = read.csv(here("data", "tidy", "pilot_data.csv"))
# Function to check for influential data points at the individual level per word type
# Plot returns the index (row no.) of the influence of indvidual data points on an
# intercept only model for RT
p_data %>%
group_by(type) %>%
summarize(mean_rt = mean(key_resp_lextale_trial.rt),
sd_rt = sd(key_resp_lextale_trial.rt))
library(lmerTest)
p_data = read.csv(here("data", "tidy", "pilot_data.csv")) %>%
mutate(type =
case_when(type == "three_way_cognate" ~ "cognate",
type == "two_way_cognate" ~ "cognate",
type == "pseudoword" ~ "pseudoword",
type == "non_cognate" ~ "non_cognate"))
p_data %>%
group_by(type) %>%
summarize(mean_rt = mean(key_resp_lextale_trial.rt),
sd_rt = sd(key_resp_lextale_trial.rt))
library(lmerTest)
p_data = read.csv(here("data", "tidy", "pilot_data.csv"))
# Function to check for influential data points at the individual level per word type
# Plot returns the index (row no.) of the influence of indvidual data points on an
# intercept only model for RT
p_data %>%
group_by(type) %>%
summarize(mean_rt = mean(key_resp_lextale_trial.rt),
sd_rt = sd(key_resp_lextale_trial.rt))
library(lmerTest)
p_data = read.csv(here("data", "tidy", "pilot_data.csv"))
# Function to check for influential data points at the individual level per word type
# Plot returns the index (row no.) of the influence of indvidual data points on an
# intercept only model for RT
p_data %>%
group_by(type) %>%
summarize(mean_rt = mean(key_resp_lextale_trial.rt),
sd_rt = sd(key_resp_lextale_trial.rt))
library(lmerTest)
p_data = read.csv(here("data", "tidy", "pilot_data.csv")) %>%
mutate(type =
case_when(type == "three_way_cognate" ~ "cognate",
type == "two_way_cognate" ~ "cognate",
type == "pseudoword" ~ "pseudoword",
type == "non_cognate" ~ "non_cognate"))
p_data %>%
group_by(type) %>%
summarize(mean_rt = mean(key_resp_lextale_trial.rt),
sd_rt = sd(key_resp_lextale_trial.rt))
library(lmerTest)
p_data = read.csv(here("data", "tidy", "pilot_data.csv"))
# Function to check for influential data points at the individual level per word type
# Plot returns the index (row no.) of the influence of indvidual data points on an
# intercept only model for RT
p_data %>%
group_by(type) %>%
summarize(mean_rt = mean(key_resp_lextale_trial.rt),
sd_rt = sd(key_resp_lextale_trial.rt))
library(lmerTest)
p_data = read.csv(here("data", "tidy", "pilot_data.csv")) %>%
mutate(type =
case_when(type == "three_way_cognate" ~ "cognate",
type == "two_way_cognate" ~ "cognate",
type == "pseudoword" ~ "pseudoword",
type == "non_cognate" ~ "non_cognate"))
p_data %>%
group_by(type) %>%
summarize(mean_rt = mean(key_resp_lextale_trial.rt),
sd_rt = sd(key_resp_lextale_trial.rt))
library(lmerTest)
p_data = read.csv(here("data", "tidy", "pilot_data.csv")) %>%
mutate(type =
case_when(type == "three_way_cognate" ~ "cognate",
type == "two_way_cognate" ~ "cognate",
type == "pseudoword" ~ "pseudoword",
type == "non_cognate" ~ "non_cognate"))
# Function to check for influential data points at the individual level per word type
# Plot returns the index (row no.) of the influence of indvidual data points on an
# intercept only model for RT
p_data %>%
group_by(type) %>%
summarize(mean_rt = mean(key_resp_lextale_trial.rt),
sd_rt = sd(key_resp_lextale_trial.rt))
library(lmerTest)
p_data = read.csv(here("data", "tidy", "pilot_data.csv")) %>%
mutate(type =
case_when(type == "three_way_cognate" ~ "cognate",
type == "two_way_cognate" ~ "cognate",
type == "pseudoword" ~ "pseudoword",
type == "non_cognate" ~ "non_cognate"))
p_data %>%
group_by(type) %>%
summarize(mean_rt = mean(key_resp_lextale_trial.rt),
sd_rt = sd(key_resp_lextale_trial.rt))
library(lmerTest)
p_data = read.csv(here("data", "tidy", "pilot_data.csv")) %>%
mutate(type =
case_when(type == "three_way_cognate" ~ "cognate",
type == "two_way_cognate" ~ "cognate",
type == "pseudoword" ~ "pseudoword",
type == "non_cognate" ~ "non_cognate"))
# Function to check for influential data points at the individual level per word type
# Plot returns the index (row no.) of the influence of indvidual data points on an
# intercept only model for RT
p_data %>%
group_by(type) %>%
summarize(mean_rt = mean(key_resp_lextale_trial.rt),
sd_rt = sd(key_resp_lextale_trial.rt))
library(lmerTest)
p_data = read.csv(here("data", "tidy", "pilot_data.csv")) %>%
mutate(type =
case_when(type == "three_way_cognate" ~ "cognate",
type == "two_way_cognate" ~ "cognate",
type == "pseudoword" ~ "pseudoword",
type == "non_cognate" ~ "non_cognate"))
p_data %>%
group_by(type) %>%
summarize(mean_rt = mean(key_resp_lextale_trial.rt),
sd_rt = sd(key_resp_lextale_trial.rt))
library(lmerTest)
p_data = read.csv(here("data", "tidy", "pilot_data.csv")) %>%
mutate(type =
case_when(type == "three_way_cognate" ~ "cognate",
type == "two_way_cognate" ~ "cognate",
type == "pseudoword" ~ "pseudoword",
type == "non_cognate" ~ "non_cognate"))
# Function to check for influential data points at the individual level per word type
# Plot returns the index (row no.) of the influence of indvidual data points on an
# intercept only model for RT
p_data %>%
group_by(type) %>%
summarize(mean_rt = mean(key_resp_lextale_trial.rt),
sd_rt = sd(key_resp_lextale_trial.rt))
library(lmerTest)
p_data = read.csv(here("data", "tidy", "pilot_data.csv")) %>%
mutate(type =
case_when(type == "three_way_cognate" ~ "cognate",
type == "two_way_cognate" ~ "cognate",
type == "pseudoword" ~ "pseudoword",
type == "non_cognate" ~ "non_cognate"))
p_data %>%
group_by(type) %>%
summarize(mean_rt = mean(key_resp_lextale_trial.rt),
sd_rt = sd(key_resp_lextale_trial.rt))
## Filter for participants who got more than 70 correct trials
cdf = p_data %>%
group_by(ppt) %>%
summarize(no_correct = sum(is_correct))
unique(cdf$ppt)
# Plotting
cdf %>%
ggplot(aes(y = reorder(ppt, -no_correct), x = no_correct, fill = as.factor(ppt))) +
geom_col() +
labs(x = "ppt", y = "Number Correct", fill = "ppt") +
theme_minimal() +
coord_flip() + ggtitle("No. total correct answers (96 possible) per participant")
# Group_by for plotting purposes
cdf_m = p_data %>%
filter(ppt %in% unique(cdf$ppt)) %>%
group_by(type,ppt) %>%
summarize(mean_rt = mean(key_resp_lextale_trial.rt))
cdf_m %>%
filter(type == "non_cognate" | type == "cognate") %>%
ggplot(aes(x = type, y = mean_rt, fill = type)) + geom_col(position = "dodge") +
facet_wrap(~ppt)
## Group data
cdf_m %>%
filter(type == "non_cognate" | type == "cognate") %>%
ggplot(aes(x = type, y = mean_rt, fill = type)) + geom_col(position = "dodge")
p_data %>%
group_by(type) %>%
summarize(mean_rt = mean(key_resp_lextale_trial.rt),
sd_rt = sd(key_resp_lextale_trial.rt))
p_data %>%
filter(ppt %in% unique(cdf$ppt)) %>%
group_by(type,ppt) %>%
summarize(mean_rt = mean(key_resp_lextale_trial.rt))
library(lmerTest)
p_data = read.csv(here("data", "tidy", "pilot_data.csv")) %>%
mutate(type =
case_when(type == "three_way_cognate" ~ "cognate",
type == "two_way_cognate" ~ "cognate",
type == "pseudoword" ~ "pseudoword",
type == "non_cognate" ~ "non_cognate"))
p_data %>%
group_by(type) %>%
summarize(mean_rt = mean(key_resp_lextale_trial.rt),
sd_rt = sd(key_resp_lextale_trial.rt))
library(lmerTest)
p_data = read.csv(here("data", "tidy", "pilot_data.csv")) %>%
mutate(type =
case_when(type == "three_way_cognate" ~ "cognate",
type == "two_way_cognate" ~ "cognate",
type == "pseudoword" ~ "pseudoword",
type == "non_cognate" ~ "non_cognate"))
## Filter for participants who got more than 70 correct trials
cdf = p_data %>%
group_by(ppt) %>%
summarize(no_correct = sum(is_correct))
library(lmerTest)
p_data = read.csv(here("data", "tidy", "pilot_data.csv")) %>%
mutate(type =
case_when(type == "three_way_cognate" ~ "cognate",
type == "two_way_cognate" ~ "cognate",
type == "pseudoword" ~ "pseudoword",
type == "non_cognate" ~ "non_cognate"))
# intercept only model for RT
p_data %>%
group_by(type) %>%
summarize(mean_rt = mean(key_resp_lextale_trial.rt),
sd_rt = sd(key_resp_lextale_trial.rt))
p_data %>%
group_by(type) %>%
summarize(mean_rt = mean(key_resp_lextale_trial.rt),
sd_rt = sd(key_resp_lextale_trial.rt)) %>%
ggplot(aes(x = type, y = mean_rt, fill = type)) + geom_col(position = "dodge")
View(p_data)
library(lmerTest)
p_data = read.csv(here("data", "tidy", "pilot_data.csv"))
# Function to check for influential data points at the individual level per word type
# Plot returns the index (row no.) of the influence of indvidual data points on an
# intercept only model for RT
p_data %>%
group_by(type) %>%
summarize(mean_rt = mean(key_resp_lextale_trial.rt),
sd_rt = sd(key_resp_lextale_trial.rt))
library(lmerTest)
p_data = read.csv(here("data", "tidy", "pilot_data.csv"))
# intercept only model for RT
p_data %>%
group_by(type) %>%
summarize(mean_rt = mean(key_resp_lextale_trial.rt),
sd_rt = sd(key_resp_lextale_trial.rt)) %>%
ggplot(aes(x = type, y = mean_rt, fill = type)) + geom_col(position = "dodge")
p_data %>%
group_by(type) %>%
summarize(mean_rt = mean(key_resp_lextale_trial.rt),
sd_rt = sd(key_resp_lextale_trial.rt)) %>%
ggplot(aes(x = type, y = mean_rt, fill = type)) + geom_boxplot()
p_data %>%
ggplot(aes(x = type, y = mean_rt, fill = type)) + geom_boxplot()
p_data %>%
ggplot(aes(x = type, y = key_resp_lextale_trial.rt, fill = type)) + geom_boxplot()
p_data %>%
ggplot(aes(x = key_resp_lextale_trial.rt, fill = type)) +
geom_density(alpha = 0.5) +
labs(x = "Response Time (s)", y = "Density", fill = "Type") +
theme_minimal()
library(tidyverse)
library(here)
# Step 1: Read in the data
tidy_data <- fs::dir_ls(here("data", "raw"),
regexp = "\\.csv$") %>%
map_dfr(read_csv, .id = "source",
col_types = cols(.default = "c"))
# Step 2: Create a unique participant ID for each source
unique_sources <- tidy_data %>% distinct(source) %>%
mutate(ppt = row_number())
# Step 3: Merge the unique IDs back to the main dataframe
tidy_data <- tidy_data %>%
left_join(unique_sources, by = "source") %>%
select(ppt, source, word, type, correct_reponse, key_resp_lextale_trial.keys, key_resp_lextale_trial.corr, key_resp_lextale_trial.rt) %>%
filter(!is.na(key_resp_lextale_trial.keys)) %>%
mutate(is_correct =
ifelse(
correct_reponse == 1 & key_resp_lextale_trial.keys == 1 |
correct_reponse == 0 & key_resp_lextale_trial.keys == 0, 1, 0)) %>%
filter(key_resp_lextale_trial.rt < 2 & key_resp_lextale_trial.rt > 0.3)  %>%  # no trials longer than 2s or less than 300ms
filter(is_correct == 1) # filter for only correct answers %>%
# Check the final dataframe
print(tidy_data)
## Create Log RTS
tidy_data$key_resp_lextale_trial.rt = as.numeric(tidy_data$key_resp_lextale_trial.rt)
tidy_data$log_rt = log(tidy_data$key_resp_lextale_trial.rt)
tidy_data = tidy_data %>%
filter(key_resp_lextale_trial.rt < 1.5 & key_resp_lextale_trial.rt > 0.3)
## Filter for participants who got more than 70 correct trials
cdf = tidy_data %>%
group_by(ppt) %>%
summarize(no_correct = sum(is_correct)) %>%
filter(no_correct > 50)
tidy_data %>%
filter(ppt %in% unique(cdf$ppt)) %>%
write.csv(here("data", "tidy", "pilot_data.csv"))
library(tidyverse)
library(here)
# Step 1: Read in the data
tidy_data <- fs::dir_ls(here("data", "raw"),
regexp = "\\.csv$") %>%
map_dfr(read_csv, .id = "source",
col_types = cols(.default = "c"))
# Step 2: Create a unique participant ID for each source
unique_sources <- tidy_data %>% distinct(source) %>%
mutate(ppt = row_number())
# Step 3: Merge the unique IDs back to the main dataframe
tidy_data <- tidy_data %>%
left_join(unique_sources, by = "source") %>%
select(ppt, source, word, type, correct_reponse, key_resp_lextale_trial.keys, key_resp_lextale_trial.corr, key_resp_lextale_trial.rt) %>%
filter(!is.na(key_resp_lextale_trial.keys)) %>%
mutate(is_correct =
ifelse(
correct_reponse == 1 & key_resp_lextale_trial.keys == 1 |
correct_reponse == 0 & key_resp_lextale_trial.keys == 0, 1, 0)) %>%
filter(key_resp_lextale_trial.rt < 2 & key_resp_lextale_trial.rt > 0.3)  %>%  # no trials longer than 2s or less than 300ms
filter(is_correct == 1) # filter for only correct answers %>%
# Check the final dataframe
print(tidy_data)
## Create Log RTS
tidy_data$key_resp_lextale_trial.rt = as.numeric(tidy_data$key_resp_lextale_trial.rt)
tidy_data$log_rt = log(tidy_data$key_resp_lextale_trial.rt)
tidy_data = tidy_data %>%
filter(key_resp_lextale_trial.rt < 1.5 & key_resp_lextale_trial.rt > 0.3)
## Filter for participants who got more than 70 correct trials
cdf = tidy_data %>%
group_by(ppt) %>%
summarize(no_correct = sum(is_correct)) %>%
filter(no_correct > 50)
library(lmerTest)
p_data = read.csv(here("data", "tidy", "pilot_data.csv"))
# intercept only model for RT
p_data %>%
group_by(type) %>%
summarize(mean_rt = mean(key_resp_lextale_trial.rt),
sd_rt = sd(key_resp_lextale_trial.rt)) %>%
ggplot(aes(x = type, y = mean_rt, fill = type)) + geom_col(position = "dodge")
p_data %>%
ggplot(aes(x = type, y = key_resp_lextale_trial.rt, fill = type)) + geom_boxplot()
p_data %>%
ggplot(aes(x = key_resp_lextale_trial.rt, fill = type)) +
geom_density(alpha = 0.5) +
labs(x = "Response Time (s)", y = "Density", fill = "Type") +
theme_minimal()
cdf = p_data %>%
group_by(ppt) %>%
summarize(no_correct = sum(is_correct))
unique(cdf$ppt)
cdf %>%
ggplot(aes(y = reorder(ppt, -no_correct), x = no_correct, fill = as.factor(ppt))) +
geom_col() +
labs(x = "ppt", y = "Number Correct", fill = "ppt") +
theme_minimal() +
coord_flip() + ggtitle("No. total correct answers (96 possible) per participant")
# Group_by for plotting purposes
cdf_m = p_data %>%
filter(ppt %in% unique(cdf$ppt)) %>%
group_by(type,ppt) %>%
summarize(mean_rt = mean(key_resp_lextale_trial.rt))
cdf_m %>%
filter(type == "non_cognate" | type == "cognate") %>%
ggplot(aes(x = type, y = mean_rt, fill = type)) + geom_col(position = "dodge") +
facet_wrap(~ppt)
cdf_m %>%
#  filter(type == "non_cognate" | type == "cognate") %>%
ggplot(aes(x = type, y = mean_rt, fill = type)) + geom_col(position = "dodge") +
facet_wrap(~ppt)
## Group data
cdf_m %>%
#  filter(type == "non_cognate" | type == "cognate") %>%
ggplot(aes(x = type, y = mean_rt, fill = type)) + geom_col(position = "dodge")
p_data
library(lmerTest)
model = lmerTest::lmer(log_rt ~ type + (1 | source) + (1 | word), data = p_data)
summary(model) # There is an effect for two-way cognates, but not 3
library(tidyverse)
library(here)
# Step 1: Read in the data
tidy_data <- fs::dir_ls(here("data", "raw"),
regexp = "\\.csv$") %>%
map_dfr(read_csv, .id = "source",
col_types = cols(.default = "c"))
# Step 2: Create a unique participant ID for each source
unique_sources <- tidy_data %>% distinct(source) %>%
mutate(ppt = row_number())
# Step 3: Merge the unique IDs back to the main dataframe
tidy_data <- tidy_data %>%
left_join(unique_sources, by = "source") %>%
select(ppt, source, word, type, correct_reponse, key_resp_lextale_trial.keys, key_resp_lextale_trial.corr, key_resp_lextale_trial.rt) %>%
filter(!is.na(key_resp_lextale_trial.keys)) %>%
mutate(is_correct =
ifelse(
correct_reponse == 1 & key_resp_lextale_trial.keys == 1 |
correct_reponse == 0 & key_resp_lextale_trial.keys == 0, 1, 0)) %>%
filter(key_resp_lextale_trial.rt < 2 & key_resp_lextale_trial.rt > 0.3)  %>%  # no trials longer than 2s or less than 300ms
filter(is_correct == 1) # filter for only correct answers %>%
# Check the final dataframe
print(tidy_data)
## Create Log RTS
tidy_data$key_resp_lextale_trial.rt = as.numeric(tidy_data$key_resp_lextale_trial.rt)
tidy_data$log_rt = log(tidy_data$key_resp_lextale_trial.rt)
tidy_data = tidy_data %>%
filter(key_resp_lextale_trial.rt < 2 & key_resp_lextale_trial.rt > 0.3)
## Filter for participants who got more than 70 correct trials
cdf = tidy_data %>%
group_by(ppt) %>%
summarize(no_correct = sum(is_correct)) %>%
filter(no_correct > 50)
tidy_data %>%
filter(ppt %in% unique(cdf$ppt)) %>%
write.csv(here("data", "tidy", "pilot_data.csv"))
library(lmerTest)
p_data = read.csv(here("data", "tidy", "pilot_data.csv"))
# intercept only model for RT
p_data %>%
group_by(type) %>%
summarize(mean_rt = mean(key_resp_lextale_trial.rt),
sd_rt = sd(key_resp_lextale_trial.rt)) %>%
ggplot(aes(x = type, y = mean_rt, fill = type)) + geom_col(position = "dodge")
p_data %>%
ggplot(aes(x = type, y = key_resp_lextale_trial.rt, fill = type)) + geom_boxplot()
p_data %>%
ggplot(aes(x = key_resp_lextale_trial.rt, fill = type)) +
geom_density(alpha = 0.5) +
labs(x = "Response Time (s)", y = "Density", fill = "Type") +
theme_minimal()
## Filter for participants who got more than 70 correct trials
cdf = p_data %>%
group_by(ppt) %>%
summarize(no_correct = sum(is_correct))
unique(cdf$ppt)
# Plotting
cdf %>%
ggplot(aes(y = reorder(ppt, -no_correct), x = no_correct, fill = as.factor(ppt))) +
geom_col() +
labs(x = "ppt", y = "Number Correct", fill = "ppt") +
theme_minimal() +
coord_flip() + ggtitle("No. total correct answers (96 possible) per participant")
## Model
library(lmerTest)
model = lmerTest::lmer(log_rt ~ type + (1 | source) + (1 | word), data = p_data)
summary(model) #
model = lmerTest::lmer(log_rt ~ type + (1 | ppt) + (1 | word) + (ppt | type), data = p_data)
model = lmerTest::lmer(log_rt ~ type + (1 | word) + (ppt | type), data = p_data)
p_data %>%
group_by(ppt, type) %>%
summarize(mean_rt_ppt = mean(key_resp_lextale_trial.rt))
p_data %>%
group_by(ppt, type) %>%
summarize(mean_rt_ppt = mean(key_resp_lextale_trial.rt)) %>%
pivot_wider(cols = c("type, mean_rt_ppt"), names_from = type, values_from = mean_rt_ppt)
p_data %>%
group_by(ppt, type) %>%
summarize(mean_rt_ppt = mean(key_resp_lextale_trial.rt)) %>%
pivot_wider(cols = c("type, mean_rt_ppt"), names_from = type, values_from = mean_rt_ppt))
p_data %>%
group_by(ppt, type) %>%
summarize(mean_rt_ppt = mean(key_resp_lextale_trial.rt)) %>%
pivot_wider(cols = c("type, mean_rt_ppt"), names_from = type, values_from = mean_rt_ppt)
p_data %>%
group_by(ppt, type) %>%
summarize(mean_rt_ppt = mean(key_resp_lextale_trial.rt)) %>%
pivot_wider(names_from = type, values_from = mean_rt_ppt)
p_data %>%
group_by(ppt, type) %>%
summarize(mean_rt_ppt = mean(key_resp_lextale_trial.rt), n_correct = n()) %>%
pivot_wider(names_from = type, values_from = mean_rt_ppt)
p_data %>%
group_by(ppt, type) %>%
summarize(mean_rt_ppt = mean(key_resp_lextale_trial.rt), n_correct = n())
p_data %>%
group_by(ppt, type) %>%
summarize(mean_rt_ppt = mean(key_resp_lextale_trial.rt)) %>%
pivot_wider(names_from = type, values_from = mean_rt_ppt)
p_data %>%
group_by(ppt, type) %>%
summarize(mean_rt_ppt = mean(key_resp_lextale_trial.rt)) %>%
pivot_wider(names_from = type, values_from = mean_rt_ppt) %>%
mutate(eff_two = two_way_cognate - non_cognate,
eff_three = three_way_cognate - non_cognate)
eff_df = p_data %>%
group_by(ppt, type) %>%
summarize(mean_rt_ppt = mean(key_resp_lextale_trial.rt)) %>%
pivot_wider(names_from = type, values_from = mean_rt_ppt) %>%
mutate(eff_two = two_way_cognate - non_cognate,
eff_three = three_way_cognate - non_cognate)
View(eff_df)
no_correct = p_data %>%
group_by(ppt, type) %>%
summarize(n = n())
no_correct
no_correct = p_data %>%
group_by(ppt) %>%
summarize(n = n())
no_correct
eff_df %>%
left_join(no_correct, by = "ppt")
eff_df %>%
left_join(no_correct, by = "ppt") %>%
ggplot(aes(x = n, y = eff_l2)) + geom_point()
eff_df %>%
left_join(no_correct, by = "ppt") %>%
ggplot(aes(x = n, y = eff_two)) + geom_point()
eff_df %>%
left_join(no_correct, by = "ppt") %>%
ggplot(aes(x = n, y = eff_two)) + geom_point() + geom_smooth()
eff_df %>%
left_join(no_correct, by = "ppt") %>%
ggplot(aes(x = n, y = eff_two)) + geom_point() + geom_smooth(method = "lm")
eff_df %>%
left_join(no_correct, by = "ppt") %>%
ggplot(aes(x = n, y = eff_three)) + geom_point() + geom_smooth(method = "lm")
eff_df %>%
left_join(no_correct, by = "ppt") %>%
ggplot(aes(x = n, y = eff_two)) + geom_point() + geom_smooth(method = "lm")
## Model
library(lmerTest)
model = lmerTest::lmer(log_rt ~ type + (1 | word) + (ppt | type), data = p_data)
summary(model) # There is an effect for two-way cognates, but not 3
p_data
model = lmerTest::lmer(log_rt ~ type + (1 | word) + (1 | ppt), data = p_data)
library(lmerTest)
model = lmerTest::lmer(log_rt ~ type + (1 | word) + (1 | ppt), data = p_data)
summary(model) # There is an effect for two-way cognates, but not 3
